from typing import List, Tuple, Union, TYPE_CHECKING

import numpy as np
import matplotlib.pyplot as plt

from deepdiagnostics.plots.plot import Display
from deepdiagnostics.utils.config import get_item
from deepdiagnostics.utils.utils import DataDisplay

if TYPE_CHECKING:
    from matplotlib.figure import Figure as fig
    from matplotlib.axes import Axes as ax


class CovarianceRankHistogram(Display):
    """
    Rank histograms to diagnose (mis)specified covariance structure.

    This implements the idea illustrated in Fig. 5 of Hamill (2001), where
    single-location rank histograms may look uniform when variances are correct,
    yet combinations (e.g., differences across paired dimensions) reveal
    misspecified covariances.

    Typical usage:

        from deepdiagnostics.plots import CovarianceRankHistogram
        CovarianceRankHistogram(model, data, save=False, show=True)()

    Notes
    -----
    - For each simulation, we:
        1) pick a random index from the provided dataset,
        2) draw posterior samples from the model for that context,
        3) compute a rank for the truth value relative to the sampled ensemble.
    - Ranks are tallied for each requested "transformation":
        - identity: per-parameter histograms (optional)
        - differences: histograms of (param_i - param_j) across provided pairs (default)
    - Ties (rare with continuous posteriors) are handled by randomizing a rank within
      the [left, right] tie block to avoid systematic bias.
    """

    def __init__(
        self,
        model,
        data,
        run_id,
        save,
        show,
        out_dir=None,
        percentiles=None,            # unused here but kept for Display signature consistency
        use_progress_bar=None,
        samples_per_inference=None,
        number_simulations=None,
        parameter_names=None,
        parameter_colors=None,
        colorway=None,
        # New options specific to this plot
        include_identity: bool = True,
        include_differences: bool = True,
        parameter_pairs: Union[None, List[Tuple[int, int]]] = None,
        difference_label: str = "{a} - {b}",
        hist_norm: str = "probability",  # "probability" or "count"
    ):
        super().__init__(
            model,
            data,
            run_id,
            save,
            show,
            out_dir,
            percentiles,
            use_progress_bar,
            samples_per_inference,
            number_simulations,
            parameter_names,
            parameter_colors,
            colorway,
        )
        self.line_cycle = tuple(get_item("plots_common", "line_style_cycle", raise_exception=False))
        self.include_identity = include_identity
        self.include_differences = include_differences
        self.parameter_pairs = parameter_pairs
        self.difference_label = difference_label
        self.hist_norm = hist_norm

        # set default pairs if not provided: all unique unordered pairs (i < j)
        if self.parameter_pairs is None and self.include_differences:
            self.parameter_pairs = [(i, j) for i in range(self.data.n_dims) for j in range(i + 1, self.data.n_dims)]

    def plot_name(self):
        return "covariance_rank_histogram.png"

    # ---------------------------
    # Internal computation utils
    # ---------------------------

    def _rank_of_value(self, ensemble: np.ndarray, truth_value: float, rng: np.random.Generator) -> int:
        """
        Compute the rank j in {0, 1, ..., n} where the truth_value would be inserted
        into the sorted ensemble. Ties are handled by randomizing within the tie block.
        """
        sorted_vals = np.sort(ensemble)
        left = np.searchsorted(sorted_vals, truth_value, side="left")
        right = np.searchsorted(sorted_vals, truth_value, side="right")
        if right == left:
            return left
        # Randomize within tie block to avoid bias
        return int(rng.integers(left, right + 1))

    def _tally_histogram(
        self,
        transforms: List[Tuple[str, callable]],
        **kwargs,
    ) -> DataDisplay:
        """
        Generate rank histograms for provided transforms.

        Parameters
        ----------
        transforms : list of (name, fn)
            Each fn takes (theta_true: (n_dims,), posterior_samples: (S, n_dims)) -> (truth_scalar, ensemble_1d)
        """
        S = self.samples_per_inference
        n_bins = S + 1  # possible ranks: 0..S
        rng = self.data.rng

        # containers
        histogram_counts = {name: np.zeros(n_bins, dtype=np.int64) for name, _ in transforms}
        total_counts = {name: 0 for name, _ in transforms}

        # main loop over pseudo-independent draws from dataset
        for _ in range(self.number_simulations):
            sample_index = rng.integers(0, len(self.data.thetas))
            theta = self.data.thetas[sample_index, :]
            x = self.data.context[sample_index, :]

            # draw ensemble from posterior for that x
            post = self.model.sample_posterior(S, x)  # (S, n_dims)

            # tally ranks for each transform
            for name, fn in transforms:
                y_true, y_ens = fn(theta, post)
                rank = self._rank_of_value(y_ens, float(y_true), rng)
                histogram_counts[name][rank] += 1
                total_counts[name] += 1

        # pack into DataDisplay
        dd_payload = {
            "ranks": np.arange(n_bins),
            "n_bins": n_bins,
            "samples_per_inference": S,
            "number_simulations": self.number_simulations,
        }
        for name in histogram_counts:
            counts = histogram_counts[name]
            dd_payload[f"hist_counts_{name}"] = counts
            dd_payload[f"hist_probs_{name}"] = counts / counts.sum() if counts.sum() > 0 else counts

        return DataDisplay(dd_payload)

    def _data_setup(self, **kwargs) -> DataDisplay:
        """
        Build the transform set and compute rank histograms.
        """
        transforms: List[Tuple[str, callable]] = []

        # Identity (per-parameter) histograms, optional
        if self.include_identity:
            for dim, pname in enumerate(self.parameter_names):
                def make_identity_fn(d=dim):
                    def fn(theta_true: np.ndarray, post: np.ndarray):
                        return theta_true[d], post[:, d]
                    return fn
                transforms.append((pname, make_identity_fn(dim)))

        # Differences histograms, optional
        if self.include_differences and self.parameter_pairs:
            for i, j in self.parameter_pairs:
                name = self.difference_label.format(a=self.parameter_names[i], b=self.parameter_names[j])

                def make_diff_fn(a=i, b=j):
                    def fn(theta_true: np.ndarray, post: np.ndarray):
                        return theta_true[a] - theta_true[b], post[:, a] - post[:, b]
                    return fn
                transforms.append((name, make_diff_fn(i, j)))

        return self._tally_histogram(transforms, **kwargs)

    # ---------------------------
    # Plotting
    # ---------------------------

    def plot(
        self,
        data_display: Union[DataDisplay, str],
        display_parameters_separate: bool = True,
        title: str = "Covariance Rank Histogram",
        x_label: str = "Rank (0 â€¦ S)",
        y_label: str = "Frequency",
        uniform_line_color: str = "gray",
        uniform_line_style: str = "--",
        bar_alpha: float = 0.8,
        **kwargs,
    ) -> Tuple["fig", "ax"]:
        """
        Render rank histograms. If `display_parameters_separate=True`, each transform gets its own subplot.
        Otherwise, all transforms are drawn on one axis.

        Args
        ----
        data_display : DataDisplay or str
            If str, treated as HDF5 path to a saved display payload.
        display_parameters_separate : bool
            Whether to show each transform in its own subplot.
        title, x_label, y_label : str
            Figure/title labels.
        uniform_line_color, uniform_line_style : str
            Styling for the reference uniform probability line (1/(S+1)).
        bar_alpha : float
            Transparency for bars.
        """
        if not isinstance(data_display, DataDisplay):
            data_display = DataDisplay().from_h5(data_display, self.plot_name)

        # discover transform keys present in the payload
        n_bins = int(data_display["n_bins"])
        ranks = data_display["ranks"]
        S = int(data_display["samples_per_inference"])
        uniform_level = 1.0 / (S + 1) if self.hist_norm == "probability" else data_display["number_simulations"]

        # collect transform names by scanning keys
        transform_names = []
        for key in data_display.keys():
            if key.startswith("hist_probs_"):
                transform_names.append(key.replace("hist_probs_", ""))
            elif key.startswith("hist_counts_") and f"hist_probs_{key.replace('hist_counts_', '')}" not in data_display:
                # in case only counts are present
                transform_names.append(key.replace("hist_counts_", ""))

        transform_names = sorted(transform_names, key=lambda s: s.lower())

        # color/linestyle cycles
        color_cycler = iter(plt.cycler("color", self.parameter_colors if self.parameter_colors is not None else plt.rcParams['axes.prop_cycle'].by_key().get('color', ['C0','C1','C2','C3','C4'])))
        line_style_cycler = iter(plt.cycler("line_style", self.line_cycle if self.line_cycle else ["-"]))

        # figure layout
        if display_parameters_separate:
            n_plots = len(transform_names)
            row_len = self.figure_size[0] * 0.8 * max(1, n_plots)
            fig, ax = plt.subplots(
                1, n_plots,
                figsize=(row_len, self.figure_size[1]),
                squeeze=False,
            )
            axes = ax[0]
        else:
            fig, ax = plt.subplots(1, 1, figsize=self.figure_size)
            axes = [ax]

        # plotting bars
        for idx, name in enumerate(transform_names):
            ax_i = axes[idx] if display_parameters_separate else axes[0]
            color = next(color_cycler)["color"]
            _ = next(line_style_cycler)

            if self.hist_norm == "probability" and f"hist_probs_{name}" in data_display:
                vals = data_display[f"hist_probs_{name}"]
            else:
                vals = data_display[f"hist_counts_{name}"]

            ax_i.bar(ranks, vals, alpha=bar_alpha, label=name, color=color, edgecolor="black", linewidth=0.5)
            ax_i.axhline(uniform_level, color=uniform_line_color, linestyle=uniform_line_style, label="Uniform ref." if idx == 0 else None)

            ax_i.set_title(name)
            ax_i.set_xlabel(x_label)
            ax_i.set_xlim(-0.5, n_bins - 0.5)

            if self.hist_norm == "probability":
                ax_i.set_ylabel("Probability")
                ax_i.set_ylim(0, max( max(vals)*1.15, uniform_level*2.0 ))
            else:
                ax_i.set_ylabel("Count")

            if not display_parameters_separate and idx == 0:
                # In stacked mode, keep adding bars/legend entries
                pass

        # unified legend
        handles, labels = [], []
        for ax_i in axes:
            h, l = ax_i.get_legend_handles_labels()
            handles += h
            labels += l
        if handles:
            # deduplicate while preserving order
            dedup = []
            seen = set()
            for h, l in zip(handles, labels):
                if l not in seen:
                    dedup.append((h, l))
                    seen.add(l)
            fig.legend([h for h, _ in dedup], [l for _, l in dedup], loc="upper center", ncol=min(4, len(dedup)))

        fig.suptitle(title)
        fig.supxlabel(x_label)
        fig.supylabel(y_label)

        return fig, ax
